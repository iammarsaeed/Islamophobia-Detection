{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#1introduction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "# split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "# SVM classifier from scikit learn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# cross validation for kfold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# calc accuracy\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f) \n",
    "    return (data)\n",
    "\n",
    "def write_data(file, data):\n",
    "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print (stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    '@Cricket_Mann And they will see more of it no...\n",
       "1    \"Juma'at Kareem to all my Muslim brother aroun...\n",
       "2    'Thorpe becomes England head coach for Pakista...\n",
       "3    '@ParZevil Plymouth Cricket. THREE transmissions.\n",
       "4    'jungkook didnâ€™t get caught eating food duri...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename  = '../Eng-Hin-data/english-anot-shuffled'\n",
    "orig_df = pd.read_csv(filename + '.csv',  \n",
    "               delimiter=',')\n",
    "orig_df.columns = ['Text', 'Label']\n",
    "orig_df['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df[\"Text\"] = orig_df[\"Text\"].astype(str)\n",
    "orig_df[\"Label\"] = orig_df[\"Label\"].astype(str)\n",
    "df = orig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balancing data \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "def balanceClasses(xs, ys):\n",
    "    item = {}\n",
    "    new_ys = []\n",
    "    new_xs = []\n",
    "    #\"\"\"Undersample xs, ys to balance classes.\"\"\"\n",
    "    freqs = Counter(ys)\n",
    "    # the most common class  is the maximum number we want for all classes\n",
    "    max_allowable = (freqs.most_common()[0][1])\n",
    "    \n",
    "    for val in freqs.most_common(): # List\n",
    "        nums = np.random.randint(1000)\n",
    "        i = 1\n",
    "        item[val[0]] = max_allowable - val[1]\n",
    "        \n",
    "        if item[val[0]] > 0:            \n",
    "            while(item[val[0]] - i != 0): \n",
    "                nums = nums + 1\n",
    "                if ys[nums] == val[0]:\n",
    "                    i += 1\n",
    "                    new_ys.append(ys[nums])\n",
    "                    new_xs.append(xs[nums])\n",
    "    return new_xs, new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text, new_label = balanceClasses(df['Text'], df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(new_text)\n",
    "data.columns = ['Text']\n",
    "data['Label'] = new_label\n",
    "data = pd.concat([df, data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig1 = plt.figure(figsize=(6,4))\n",
    "data.groupby('Label').Text.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# People usually join sentences using more than one colon \n",
    "\n",
    "def ReplaceDoubleColon(inputString):\n",
    "    return inputString.replace(\"..\", \" \") \n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: ReplaceDoubleColon(x))\n",
    "\n",
    "def ReplaceTripleColon(inputString):\n",
    "    return inputString.replace(\"...\", \" \") \n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: ReplaceTripleColon(x))\n",
    "\n",
    "def ReplaceFourColon(inputString):\n",
    "    return inputString.replace(\"....\", \" \") \n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: ReplaceFourColon(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def textPattern(text):\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"@\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \"have\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"aren't\", \"are not\", text)\n",
    "    text = re.sub(r\"couldn't\", \"could not\", text)\n",
    "    text = re.sub(r\"didn't\", \"did not\", text)\n",
    "    text = re.sub(r\"doesn't\", \"does not\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"hadn't\", \"had not\", text)\n",
    "    text = re.sub(r\"hasn't\", \"has not\", text)\n",
    "    text = re.sub(r\"haven't\", \"have not\", text)\n",
    "    text = re.sub(r\"isn't\", \"is not\", text)\n",
    "    text = re.sub(r\"shouldn't\", \"should not\", text)\n",
    "    text = re.sub(r\"wasn't\", \"was not\", text)\n",
    "    text = re.sub(r\"weren't\", \"were not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"wouldn't\", \"would not\", text)\n",
    "    text = re.sub(r\"mustn't\", \"must not\", text)\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"\\'re\", \"are\", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\= =\", \" \", text)\n",
    "    text = re.sub(r\"\\==\", \" \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: textPattern(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRbackup my Muslim Brother I love you for the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAPPY NEW YEAR TO ALL MUSLIM UMMAH MUHARRAM M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wishing a happy new year to all Muslim member...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DChaurasia2312 Radical Muslim Terrorist Muslim</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaddar Muslim jehadi jailðŸ‘®ðŸš“ðŸ‘®ðŸš“ðŸ‘®...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Label\n",
       "0   PRbackup my Muslim Brother I love you for the...     1\n",
       "1   HAPPY NEW YEAR TO ALL MUSLIM UMMAH MUHARRAM M...     1\n",
       "2   Wishing a happy new year to all Muslim member...     1\n",
       "3     DChaurasia2312 Radical Muslim Terrorist Muslim     2\n",
       "4   Gaddar Muslim jehadi jailðŸ‘®ðŸš“ðŸ‘®ðŸš“ðŸ‘®...     2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10663\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     PRbackup my Muslim Brother I love you for the...\n",
       "1     HAPPY NEW YEAR TO ALL MUSLIM UMMAH MUHARRAM M...\n",
       "2     Wishing a happy new year to all Muslim member...\n",
       "3       DChaurasia2312 Radical Muslim Terrorist Muslim\n",
       "4     Gaddar Muslim jehadi jailðŸ‘®ðŸš“ðŸ‘®ðŸš“ðŸ‘®...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = orig_df['Text']\n",
    "\n",
    "data['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new year\n"
     ]
    }
   ],
   "source": [
    "def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = \" \".join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return (texts_out)\n",
    "\n",
    "\n",
    "lemmatized_texts = lemmatization(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'sake', 'hold', 'hand']\n"
     ]
    }
   ],
   "source": [
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "data_words = gen_words(lemmatized_texts)\n",
    "\n",
    "print (data_words[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'sake', 'hold', 'hand']\n"
     ]
    }
   ],
   "source": [
    "#BIGRAMS AND TRIGRAMS\n",
    "bigram_phrases = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram_phrases = gensim.models.Phrases(bigram_phrases[data_words], threshold=100)\n",
    "\n",
    "bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return([bigram[doc] for doc in texts])\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return ([trigram[bigram[doc]] for doc in texts])\n",
    "\n",
    "data_bigrams = make_bigrams(data_words)\n",
    "data_bigrams_trigrams = make_trigrams(data_bigrams)\n",
    "\n",
    "print (data_bigrams_trigrams[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF REMOVAL\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "id2word = corpora.Dictionary(data_bigrams_trigrams)\n",
    "\n",
    "texts = data_bigrams_trigrams\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# print (corpus[0][0:20])\n",
    "\n",
    "tfidf = TfidfModel(corpus, id2word=id2word)\n",
    "\n",
    "low_value = 0.03\n",
    "words  = []\n",
    "words_missing_in_tfidf = []\n",
    "for i in range(0, len(corpus)):\n",
    "    bow = corpus[i]\n",
    "    low_value_words = [] #reinitialize to be safe.\n",
    "    tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "    bow_ids = [id for id, value in bow]\n",
    "    low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    drops = low_value_words+words_missing_in_tfidf\n",
    "    for item in drops:\n",
    "        words.append(id2word[item])\n",
    "    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids] # The words with tf-idf socre 0 will be missing\n",
    "\n",
    "    new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tfidf]\n",
    "    corpus[i] = new_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10663"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus[:-1],\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=\"auto\")\n",
    "\n",
    "\n",
    "# lda_model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus[i],\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=10,\n",
    "#                                            chunksize=100,\n",
    "#                                            workers=7, # Num. Processing Cores - 1\n",
    "#                                            passes=50,\n",
    "#                                            eval_every = 1,\n",
    "#                                            per_word_topics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_doc = corpus[-1]\n",
    "\n",
    "# vector = lda_model[test_doc]\n",
    "# print (vector)\n",
    "# # For topic importance\n",
    "# def Sort(sub_li):\n",
    "#     sub_li.sort(key = lambda x: x[1])\n",
    "#     sub_li.reverse()\n",
    "#     return (sub_li)\n",
    "# new_vector = Sort(vector)\n",
    "# print (new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save(\"test_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = gensim.models.ldamodel.LdaModel.load(\"test_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model.print_topics(20,num_words=15)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "for i in range(len(data)):\n",
    "    top_topics = new_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(10)]\n",
    "    topic_vec.extend([len(data.iloc[i].Text)]) # length review\n",
    "    train_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09562685,\n",
       " 0.018086337,\n",
       " 0.23975855,\n",
       " 0.19146949,\n",
       " 0.040576503,\n",
       " 0.08423805,\n",
       " 0.020207353,\n",
       " 0.20302707,\n",
       " 0.0320283,\n",
       " 0.07498153,\n",
       " 100]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using similar split 90/10\n",
    "labels = data.Label\n",
    "X = np.array(train_vecs)\n",
    "y = np.array(data.Label)\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(X, y, data.index, test_size=0.30, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train_scale = scaler.fit_transform(X_train)\n",
    "# X_test_scale = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = LinearSVC(random_state=10, tol=1e-5, verbose=1, max_iter=100000)\n",
    "# clf2 = model2.fit(X_train, y_train)\n",
    "# y_pred2 = model2.predict(X_test)\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel='linear', random_state=10, tol=1e-3)\n",
    "\n",
    "#Fitting training set to the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "#Predicting the test set results based on the model\n",
    "y_pred2 = svm_model.predict(X_test)\n",
    "\n",
    "#Calculate the accuracy score of this model\n",
    "score = accuracy_score(y_test,y_pred2)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[818 152 159]\n",
      " [255 601 192]\n",
      " [184  99 739]]\n",
      "Accuracy Score : 0.6745858080650203\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.72      0.69      1129\n",
      "           1       0.71      0.57      0.63      1048\n",
      "           2       0.68      0.72      0.70      1022\n",
      "\n",
      "    accuracy                           0.67      3199\n",
      "   macro avg       0.68      0.67      0.67      3199\n",
      "weighted avg       0.68      0.67      0.67      3199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results2 = confusion_matrix(y_test, y_pred2)\n",
    "print ('Confusion Matrix :')\n",
    "print(results2) \n",
    "print ('Accuracy Score :',accuracy_score(y_test, y_pred2))\n",
    "print ('Report : ')\n",
    "print (classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_doc = corpus[-1]\n",
    "\n",
    "# vector = new_model[test_doc]\n",
    "# print (vector)\n",
    "\n",
    "# def Sort(sub_li):\n",
    "#     sub_li.sort(key = lambda x: x[1])\n",
    "#     sub_li.reverse()\n",
    "#     return (sub_li)\n",
    "# new_vector = Sort(vector)\n",
    "# print (new_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el771091406533345271042543378252\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el771091406533345271042543378252_data = {\"mdsDat\": {\"x\": [-0.06390738705910827, -0.041657568779344796, -0.36497523741888377, -0.3133632982753684, 0.26215029892093766, 0.3898493615751351, 0.228446584332657, -0.017743740326789742, -0.22367164628306893, 0.1448726333138343], \"y\": [0.45251356321598984, -0.44458085270524034, -0.20960528750579577, 0.23506635223095543, -0.27311522204695393, -0.007785977088800276, 0.2880721834845181, -0.12690656902749206, 0.01762621116358667, 0.0687155982792323], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [28.389557959538692, 18.1836597460361, 9.071633769231559, 9.033115115617713, 8.669373938085, 6.93390550571342, 6.849594705158411, 4.62446947248412, 4.447175145736634, 3.7975146423983515]}, \"tinfo\": {\"Term\": [\"be\", \"\\u00f0y\", \"cricket\", \"muslim\", \"happy\", \"year\", \"new\", \"terrorist\", \"brother\", \"islamic\", \"do\", \"have\", \"good\", \"radical\", \"sister\", \"why\", \"call\", \"wish\", \"muharram\", \"jehadi\", \"world\", \"terrorism\", \"see\", \"think\", \"take\", \"come\", \"say\", \"so\", \"verse\", \"start\", \"be\", \"muslim\", \"terrorist\", \"have\", \"radical\", \"jehadi\", \"terrorism\", \"say\", \"go\", \"know\", \"want\", \"don\", \"man\", \"then\", \"ia\", \"group\", \"ita\", \"big\", \"mean\", \"forget\", \"rape\", \"person\", \"bangaloreriot\", \"nation\", \"hindu\", \"american\", \"word\", \"brotherhood\", \"threat\", \"police\", \"islamic\", \"cricket\", \"do\", \"so\", \"just\", \"make\", \"get\", \"people\", \"day\", \"now\", \"play\", \"only\", \"more\", \"love\", \"how\", \"too\", \"amp\", \"always\", \"test\", \"match\", \"look\", \"leave\", \"woman\", \"show\", \"try\", \"thank\", \"legend\", \"game\", \"ve\", \"old\", \"write\", \"happy\", \"year\", \"new\", \"muharram\", \"when\", \"st\", \"country\", \"https_co\", \"first\", \"islamicnewyear\", \"kill\", \"live\", \"well\", \"become\", \"ever\", \"bad\", \"hope\", \"bless\", \"channel\", \"bring\", \"hijri\", \"free\", \"th\", \"a\\u0153\", \"englandcricket\", \"travel_ban\", \"tahunbaruislam\", \"beat\", \"ah\", \"birthday\", \"islamic\", \"\\u00f0y\", \"brother\", \"sister\", \"support\", \"today\", \"place\", \"ban\", \"name\", \"friend\", \"player\", \"much\", \"like\", \"miss\", \"again\", \"khanumarfa\", \"girl\", \"ecb_cricket\", \"claim\", \"real\", \"family\", \"white\", \"send\", \"home\", \"mention\", \"destroy\", \"blessing\", \"ball\", \"hard\", \"dear\", \"accept\", \"why\", \"see\", \"time\", \"extremist\", \"end\", \"quran\", \"win\", \"great\", \"use\", \"happen\", \"watch\", \"thing\", \"help\", \"face\", \"wrong\", \"understand\", \"true\", \"believe\", \"sport\", \"run\", \"fake\", \"ipl\", \"follow\", \"dream\", \"sound\", \"season\", \"force\", \"reason\", \"dangerous\", \"long\", \"verse\", \"team\", \"fuck\", \"need\", \"give\", \"back\", \"way\", \"life\", \"work\", \"let\", \"supporter\", \"read\", \"there\", \"animal\", \"chuslim\", \"celebrate\", \"ideology\", \"all\", \"hai\", \"lot\", \"quote\", \"job\", \"community\", \"political\", \"together\", \"find\", \"everyday\", \"cow\", \"fear\", \"member\", \"good\", \"come\", \"even\", \"very\", \"here\", \"also\", \"same\", \"indian\", \"human\", \"jihadi\", \"talk\", \"msdhoni_narendramodi\", \"fight\", \"dona\", \"respect\", \"ask\", \"few\", \"organisation\", \"state\", \"msdhoni\", \"slave\", \"lose\", \"young\", \"city\", \"pisslam\", \"pure\", \"sambitswaraj\", \"host\", \"honor\", \"organization\", \"wish\", \"world\", \"take\", \"never\", \"re\", \"islam\", \"most\", \"guy\", \"tell\", \"feel\", \"last\", \"where\", \"xa\", \"cpl\", \"own\", \"law\", \"prophet\", \"isis\", \"stupid\", \"eid\", \"touch\", \"strong\", \"child\", \"enemy\", \"hsajwanization\", \"lol\", \"celebration\", \"lead\", \"parent\", \"eat_meat\", \"think\", \"other\", \"right\", \"anti\", \"still\", \"hate\", \"attack\", \"tweet\", \"allow\", \"post\", \"hell\", \"remember\", \"far\", \"proud\", \"sure\", \"wait\", \"indeed\", \"mob\", \"evil\", \"die\", \"culture\", \"bat\", \"trigger\", \"squad\", \"christian\", \"left\", \"wona\", \"mate\", \"power\", \"wake\", \"call\", \"start\", \"religion\", \"stop\", \"one\", \"month\", \"peace\", \"actually\", \"rapist\", \"account\", \"violence\", \"india\", \"riot\", \"humanity\", \"war\", \"bjp\", \"defend\", \"change\", \"history\", \"listen\", \"save\", \"fellow\", \"series\", \"cause\", \"western\", \"bowler\", \"flexible\", \"photo\", \"disgrace\", \"wonder\"], \"Freq\": [5123.0, 1521.0, 1783.0, 1870.0, 839.0, 838.0, 637.0, 1199.0, 548.0, 1258.0, 680.0, 900.0, 356.0, 657.0, 331.0, 315.0, 232.0, 222.0, 282.0, 550.0, 185.0, 463.0, 228.0, 177.0, 178.0, 202.0, 442.0, 321.0, 201.0, 157.0, 5122.9160232786235, 1869.4739341799243, 1199.0613231379173, 899.8131640367548, 656.2572169989052, 549.7793108488237, 462.9431895806514, 441.3795231296423, 278.934785810382, 215.813011575878, 212.99494401550893, 149.17771988080693, 141.91342656229529, 138.93506404084567, 136.23997783431454, 110.30165125864478, 100.49673556040251, 90.93630359070531, 87.33679809506867, 84.67684941820552, 78.49588476237963, 74.49966902059208, 68.9358154722782, 66.06183402254068, 63.06822482769494, 61.36309377337529, 59.812374734485324, 57.400607233994236, 57.210572546060675, 56.50894767248532, 1193.9033221876423, 1782.5632387116846, 679.8732452682301, 320.2059763073787, 303.19424430395657, 297.48892883965226, 280.5950474299964, 253.32196310221664, 247.69081410824697, 229.64861948933304, 222.6624903529862, 216.16818169580577, 214.10793224131737, 190.1694066913035, 171.09054679406805, 151.74544302521005, 146.2766493341824, 126.27239799900217, 124.93372096456868, 110.84863215207206, 105.56998507234644, 103.66138710381558, 95.601527555136, 87.99454686509411, 86.80040756226373, 81.85451403545731, 78.90494271344882, 74.30179457773879, 72.17340030418444, 66.24305126701984, 66.08534796120016, 838.9642286387268, 837.4474943758406, 636.172301515897, 281.98202837062274, 185.67025756218078, 178.4383653362839, 164.65351597023712, 127.63809839138223, 121.03262001683379, 96.7295506182865, 93.81347222886622, 90.78138837571088, 85.08771691952833, 67.59961482186655, 62.97391727399685, 60.811010483547655, 59.34787509157498, 57.01894003401876, 55.01905135281332, 53.34073181582627, 49.673555826202694, 48.73215303572503, 46.67796411682389, 46.32676598875724, 43.32145748979577, 43.03822270596624, 41.48192593828294, 35.19643938523252, 34.623181911591765, 32.250713951016806, 64.07998171991161, 1520.6262990135701, 547.1799647594804, 330.352261612238, 157.437755761973, 102.71541908475419, 97.81428276827515, 96.2608923618057, 92.8302869739448, 89.93362825318982, 88.51652256452329, 85.98984202308746, 85.1351820579373, 84.2778484328883, 74.87263227916648, 71.26807713954668, 58.06250521926398, 51.36158814765634, 49.70936824098022, 49.52490069484351, 47.25526317839022, 46.414675896227756, 45.677105449337745, 41.52899705071092, 40.98994285393276, 40.04341929172042, 36.17543971240439, 35.902318759510045, 35.43830388511677, 35.28133427161672, 33.86655154979053, 314.3819843880315, 228.1051840802662, 179.59865808446958, 160.64991178837346, 118.33603705848712, 114.26818191877544, 110.7432943070044, 109.2374100511375, 108.86034639116575, 103.78121178548695, 103.23366458356574, 95.26571650715616, 93.7035413841715, 84.6785861423005, 65.31275006577695, 64.63930785626471, 61.874214623320135, 59.87827648473766, 52.17105339045965, 51.26875405582373, 51.00703949589735, 49.59074079725557, 45.82404524863946, 43.18665070141771, 43.01541059272399, 42.0642853746258, 41.81215591124666, 41.24649713433705, 40.9278358243359, 40.33134191840772, 200.31049170310516, 187.91883641839922, 177.4966786916476, 147.3819842491516, 124.94787932295606, 122.59521325412389, 97.86609147733463, 85.87318582203751, 85.37916404907757, 80.5361051312507, 73.46656143556517, 73.0440627947157, 69.54907893901044, 64.64508984089181, 62.41682423229735, 61.560120404366096, 61.20834421204046, 48.281270892619084, 47.19112638451254, 47.043220799214026, 42.43589417320697, 42.15022499470743, 41.57462552850587, 41.006462296074524, 39.91207048365492, 38.48735067544619, 37.63048579047164, 36.28757145618003, 35.58181489085058, 31.881138182714118, 355.6658549987001, 201.58489317360343, 167.9824804329964, 158.57383686719697, 133.37723665830967, 129.72884851560408, 121.17833797345507, 103.11339685562002, 77.49220308169888, 67.55344713595937, 64.81075344198342, 63.49622529257526, 61.726824819416564, 55.6773824766353, 55.10015414802409, 54.43908534114078, 53.286378769807264, 47.92939313796856, 46.26419777888001, 45.96827416493976, 44.959561024002326, 44.49839748240704, 44.39054673487484, 40.37169495639502, 38.814341253483406, 38.79416753614597, 37.14856177481896, 35.765412075855615, 34.55297302757921, 34.161249257513134, 221.97732664635154, 185.10777713689473, 177.25867196759035, 129.4444483932327, 115.56150965746193, 101.05414778739829, 95.20607413419572, 62.085316070205614, 60.79287170936793, 51.075913907058556, 46.707391815195145, 44.74182556405629, 44.3552369896083, 43.63413448729342, 42.61871263786792, 40.259818307101206, 38.70113280174427, 35.673121614492295, 32.299149161340225, 31.064490840134507, 28.680952508186387, 27.35293239869429, 27.131587529801795, 26.251928654256986, 24.646352028843918, 24.18626417864331, 23.377775214355896, 22.504911085836696, 21.57022826294675, 21.215805787674647, 176.1471982103601, 156.70503045409362, 136.3129117263576, 114.26428146154305, 108.26107250694272, 101.60733106386462, 60.48857198858039, 58.229410365224716, 57.84437375551695, 47.82895948989205, 45.98906401894157, 45.21970207041671, 44.365161743568834, 41.86025160048683, 40.450778314998644, 40.14244681088718, 34.41974715837999, 31.916032304554108, 31.20660599606194, 27.15137912581161, 25.58572432885552, 25.44604076045354, 23.98815826009258, 21.687878686326457, 21.052973498123112, 20.790988228168302, 19.533265029905895, 19.431148960123974, 19.31063428979233, 19.116919220016577, 231.15453251547908, 156.94199510523876, 147.8971152597989, 89.43229509845344, 61.62208345592177, 55.000759065043326, 51.457196067469205, 40.21218061630974, 33.79155656498608, 32.68610059675128, 32.425845656646246, 31.521682272523353, 31.478639954263546, 31.272596812746645, 30.283472796667866, 27.403946997484873, 26.488939237492673, 25.348928949586913, 25.17981666653826, 25.061521486680125, 23.852561331377558, 22.614843292495, 20.27971247050125, 20.27467587157612, 20.162526174069207, 20.13775775063356, 19.821078285467408, 18.750807944399554, 18.20189678743857, 16.938698371557017], \"Total\": [5123.0, 1521.0, 1783.0, 1870.0, 839.0, 838.0, 637.0, 1199.0, 548.0, 1258.0, 680.0, 900.0, 356.0, 657.0, 331.0, 315.0, 232.0, 222.0, 282.0, 550.0, 185.0, 463.0, 228.0, 177.0, 178.0, 202.0, 442.0, 321.0, 201.0, 157.0, 5123.788443046155, 1870.34633911531, 1199.933708374778, 900.6855882355579, 657.129591265648, 550.6517191271433, 463.8155972633809, 442.25194038805785, 279.8072840359147, 216.68541249792366, 213.86737350956793, 150.0501686218928, 142.785876357513, 139.80746805773188, 137.1124150615534, 111.1740676405357, 101.3691748779212, 91.80875254568578, 88.20922927344951, 85.54931073567869, 79.36844354852941, 75.37220090745903, 69.80831079277914, 66.93426759216214, 63.94064505918019, 62.23550266443396, 60.684882376253015, 58.273009322799226, 58.08294103809937, 57.3814265210515, 1258.7663726319877, 1783.4424331852285, 680.7524723195029, 321.08519703599336, 304.0734410427653, 298.368143413901, 281.4742428904299, 254.20120449558064, 248.57004741912985, 230.52789115383968, 223.54165512346717, 217.04743652941616, 214.98716134309365, 191.0485935429577, 171.96972673094842, 152.62468388335876, 147.155872452085, 127.15161494309554, 125.81291061243601, 111.7278034688515, 106.44917112550667, 104.54073096597659, 96.48078613239485, 88.87378433533466, 87.67959233787356, 82.73369767658099, 79.7842526861099, 75.18097706500863, 73.05260527214212, 67.12239756784717, 66.96463628275878, 839.8592992250261, 838.3425742833177, 637.0673566730976, 282.8770659461824, 186.5655402162035, 179.33344157708248, 165.54872310140595, 128.53325352487963, 121.92774615451776, 97.6245905894629, 94.70870823702543, 91.67652879000981, 85.98286537114271, 68.49481771763115, 63.8691120009185, 61.70630182902816, 60.243009296204235, 57.91401000983204, 55.91422120917226, 54.2359000176953, 50.56863216372384, 49.627352198494926, 47.573101788298324, 47.22187884214432, 44.21669082704466, 43.93785909940369, 42.376988963434826, 36.0915626808951, 35.51825949122943, 33.14577794527781, 1258.7663726319877, 1521.5090959953332, 548.0627955708572, 331.23511505479917, 158.3206937318816, 103.5983261850749, 98.69722007860469, 97.14381654457908, 93.71318819324486, 90.81646797010144, 89.39938365787481, 86.87270516974148, 86.01808586009648, 85.16070293780031, 75.75557693167177, 72.1509528283976, 58.945516235000746, 52.244585358457236, 50.59236922593006, 50.407753251585746, 48.1381098874184, 47.29760239603871, 46.55999887671871, 42.412011557367514, 41.87321045664532, 40.926411605771875, 37.058330337158424, 36.78515106801394, 36.32121759290209, 36.164344825994725, 34.74943638083629, 315.2612098957483, 228.98438856768527, 180.47787504197453, 161.5291127287823, 119.21523934558957, 115.14741028877697, 111.622494253133, 110.11659357354637, 109.73955337053455, 104.660422242377, 104.11281664086718, 96.14491013809369, 94.5827511784519, 85.55783213704352, 66.19205857540949, 65.51852727851013, 62.75343812326356, 60.75752557354725, 53.05021205218208, 52.14790581435674, 51.88629571878837, 50.46990043211228, 46.70320414432437, 44.06598848046634, 43.894603833484965, 42.94353332190452, 42.69144470154809, 42.12573385041378, 41.80724149892339, 41.2105503805628, 201.1970742510656, 188.8054894287324, 178.3833112524803, 148.26865618889917, 125.83457902261323, 123.48186493261458, 98.75274578182224, 86.759806890805, 86.26579738172141, 81.42273450131701, 74.35335984382988, 73.93067246103321, 70.43577670234248, 65.53180154458133, 63.303590386376456, 62.44674473325618, 62.09513568485589, 49.16790339598162, 48.07772947722212, 47.929838551267444, 43.32251832491274, 43.03693720754488, 42.46122207889758, 41.893273620044596, 40.79867739076729, 39.37399861519225, 38.51746004147912, 37.174758934459945, 36.4685131160443, 32.76772416372549, 356.5495699537713, 202.46868486032517, 168.86623212570464, 159.45754504171157, 134.2609944177233, 130.61255105581307, 122.06215569022527, 103.99710349632774, 78.37606752720717, 68.4372178178769, 65.69448057960886, 64.37989694343288, 62.610618259898196, 56.56119203604847, 55.98389149903535, 55.32280836610648, 54.1701131907671, 48.81317817028923, 47.14790970296616, 46.85196396347673, 45.84334614181268, 45.382148837159974, 45.27460857203539, 41.25541559451449, 39.69810590510898, 39.67802180919308, 38.032262819838614, 36.65086155867271, 35.43754303954215, 35.04492589089338, 222.8654516670655, 185.99592400742205, 178.1469017156788, 130.3326389381307, 116.44969924795538, 101.9423204809823, 96.09425494096442, 62.97350538301836, 61.68102503967545, 51.96408653351401, 47.595550690770516, 45.62995471920046, 45.24348738185802, 44.52227325457043, 43.50687207187573, 41.14803925889298, 39.58936934001098, 36.56125357190169, 33.187345151422846, 31.95257834210011, 29.56936139014591, 28.241255149072984, 28.01968875887007, 27.140189263374168, 25.534604110600366, 25.074380560744757, 24.266091435718696, 23.393046172087935, 22.458476420353584, 22.10387614584394, 177.04281314470137, 157.60071564318127, 137.20847751202322, 115.15980972093938, 109.15667479492515, 102.50291172906888, 61.384111689941534, 59.12497031236684, 58.74000041283623, 48.72451468859791, 46.88482069181112, 46.115287545195635, 45.26075392840379, 42.755882429483464, 41.34640998438538, 41.038091076392554, 35.31545724322588, 32.811659026636384, 32.10227123844103, 28.046962978014584, 26.481306462829195, 26.341591112758323, 24.883968669654198, 22.58365619143479, 21.948612461505245, 21.686645368585655, 20.42883543674702, 20.326722231451875, 20.206443562335778, 20.012918183004295, 232.0516684607828, 157.83912833333838, 148.79428301709834, 90.32944504421494, 62.51921443931512, 55.89784316429571, 52.35430727878885, 41.109372645711616, 34.688898714182024, 33.58385976313385, 33.32298132495074, 32.41882006724104, 32.37577725764928, 32.16983777040197, 31.180656411121834, 28.301349570726064, 27.386115125591562, 26.24603089709027, 26.076938494997066, 25.95861695790728, 24.749635338722825, 23.51198290726007, 21.17682674366019, 21.171753443300084, 21.05965945012003, 21.034960837911797, 20.7181683695303, 19.648348559107134, 19.099780672022597, 17.835888249953488], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.3734, -2.3815, -2.8256, -3.1127, -3.4284, -3.6054, -3.7773, -3.825, -4.2839, -4.5405, -4.5536, -4.9098, -4.9597, -4.9809, -5.0005, -5.2117, -5.3048, -5.4048, -5.4451, -5.4761, -5.5519, -5.6041, -5.6817, -5.7243, -5.7707, -5.7981, -5.8237, -5.8649, -5.8682, -5.8805, -2.8299, -1.9836, -2.9475, -3.7005, -3.755, -3.774, -3.8325, -3.9348, -3.9572, -4.0329, -4.0638, -4.0934, -4.1029, -4.2215, -4.3272, -4.4472, -4.4839, -4.631, -4.6416, -4.7612, -4.81, -4.8283, -4.9092, -4.9921, -5.0058, -5.0645, -5.1012, -5.1613, -5.1903, -5.2761, -5.2785, -2.0419, -2.0437, -2.3186, -3.1322, -3.5501, -3.5898, -3.6702, -3.9248, -3.978, -4.2021, -4.2327, -4.2656, -4.3304, -4.5604, -4.6313, -4.6663, -4.6906, -4.7307, -4.7664, -4.7973, -4.8686, -4.8877, -4.9308, -4.9383, -5.0054, -5.012, -5.0488, -5.2131, -5.2295, -5.3005, -4.6139, -1.4429, -2.465, -2.9696, -3.7108, -4.1378, -4.1867, -4.2027, -4.239, -4.2707, -4.2866, -4.3156, -4.3255, -4.3357, -4.454, -4.5033, -4.7083, -4.8309, -4.8636, -4.8673, -4.9142, -4.9322, -4.9482, -5.0434, -5.0565, -5.0798, -5.1814, -5.189, -5.202, -5.2064, -5.2474, -2.9781, -3.2989, -3.538, -3.6495, -3.9552, -3.9901, -4.0215, -4.0352, -4.0386, -4.0864, -4.0917, -4.172, -4.1886, -4.2898, -4.5495, -4.5599, -4.6036, -4.6364, -4.7742, -4.7916, -4.7967, -4.8249, -4.9039, -4.9632, -4.9671, -4.9895, -4.9955, -5.0091, -5.0169, -5.0316, -3.2054, -3.2693, -3.3264, -3.5123, -3.6774, -3.6964, -3.9217, -4.0524, -4.0582, -4.1166, -4.2085, -4.2143, -4.2633, -4.3364, -4.3715, -4.3853, -4.391, -4.6283, -4.6511, -4.6542, -4.7573, -4.7641, -4.7778, -4.7916, -4.8186, -4.855, -4.8775, -4.9138, -4.9335, -5.0433, -2.6191, -3.1869, -3.3692, -3.4269, -3.5999, -3.6276, -3.6958, -3.8573, -4.1429, -4.2802, -4.3216, -4.3421, -4.3704, -4.4735, -4.4839, -4.496, -4.5174, -4.6234, -4.6587, -4.6651, -4.6873, -4.6976, -4.7001, -4.795, -4.8343, -4.8348, -4.8782, -4.9161, -4.9506, -4.962, -2.6977, -2.8793, -2.9226, -3.237, -3.3505, -3.4846, -3.5442, -3.9717, -3.9928, -4.1669, -4.2564, -4.2993, -4.308, -4.3244, -4.348, -4.4049, -4.4444, -4.5259, -4.6252, -4.6642, -4.744, -4.7914, -4.7996, -4.8325, -4.8956, -4.9145, -4.9485, -4.9865, -5.0289, -5.0455, -2.8898, -3.0068, -3.1462, -3.3226, -3.3766, -3.44, -3.9587, -3.9968, -4.0034, -4.1935, -4.2328, -4.2496, -4.2687, -4.3268, -4.3611, -4.3687, -4.5225, -4.5981, -4.6205, -4.7597, -4.8191, -4.8246, -4.8836, -4.9844, -5.0141, -5.0266, -5.089, -5.0943, -5.1005, -5.1106, -2.4602, -2.8474, -2.9067, -3.4098, -3.7822, -3.8959, -3.9625, -4.2091, -4.383, -4.4163, -4.4243, -4.4526, -4.4539, -4.4605, -4.4926, -4.5926, -4.6265, -4.6705, -4.6772, -4.6819, -4.7313, -4.7846, -4.8936, -4.8939, -4.8994, -4.9006, -4.9165, -4.972, -5.0017, -5.0736], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.259, 1.2587, 1.2584, 1.2582, 1.2578, 1.2576, 1.2573, 1.2572, 1.256, 1.2551, 1.2551, 1.2533, 1.253, 1.2529, 1.2528, 1.2513, 1.2505, 1.2496, 1.2492, 1.2489, 1.2481, 1.2475, 1.2466, 1.246, 1.2454, 1.245, 1.2447, 1.2441, 1.244, 1.2438, 1.2062, 1.7042, 1.7034, 1.7019, 1.7018, 1.7017, 1.7015, 1.7012, 1.7011, 1.7008, 1.7007, 1.7006, 1.7005, 1.7, 1.6995, 1.6989, 1.6987, 1.6977, 1.6976, 1.6967, 1.6964, 1.6962, 1.6955, 1.6947, 1.6946, 1.694, 1.6936, 1.6929, 1.6925, 1.6915, 1.6914, 2.399, 2.3989, 2.3986, 2.3968, 2.3952, 2.395, 2.3946, 2.393, 2.3926, 2.3908, 2.3905, 2.3902, 2.3896, 2.3869, 2.3859, 2.3854, 2.385, 2.3844, 2.3839, 2.3834, 2.3822, 2.3818, 2.381, 2.3809, 2.3796, 2.3793, 2.3787, 2.3749, 2.3745, 2.3726, -0.5777, 2.4037, 2.4027, 2.4016, 2.3987, 2.3957, 2.3953, 2.3951, 2.3948, 2.3945, 2.3943, 2.3941, 2.394, 2.3939, 2.3925, 2.392, 2.3892, 2.3872, 2.3867, 2.3866, 2.3858, 2.3854, 2.3851, 2.3832, 2.383, 2.3825, 2.3802, 2.38, 2.3797, 2.3796, 2.3785, 2.4426, 2.4415, 2.4405, 2.4399, 2.438, 2.4377, 2.4375, 2.4374, 2.4373, 2.4369, 2.4369, 2.4362, 2.436, 2.435, 2.432, 2.4319, 2.4313, 2.4308, 2.4287, 2.4284, 2.4283, 2.4278, 2.4264, 2.4252, 2.4251, 2.4247, 2.4246, 2.4243, 2.4241, 2.4238, 2.6643, 2.664, 2.6638, 2.6627, 2.6617, 2.6615, 2.6597, 2.6585, 2.6584, 2.6578, 2.6567, 2.6567, 2.6561, 2.6551, 2.6546, 2.6544, 2.6544, 2.6505, 2.6501, 2.6501, 2.6481, 2.6479, 2.6476, 2.6474, 2.6468, 2.646, 2.6454, 2.6446, 2.6441, 2.6413, 2.6785, 2.6766, 2.6757, 2.6754, 2.6744, 2.6742, 2.6737, 2.6724, 2.6696, 2.668, 2.6674, 2.6672, 2.6668, 2.6652, 2.6651, 2.6649, 2.6645, 2.6627, 2.6621, 2.6619, 2.6615, 2.6613, 2.6613, 2.6593, 2.6585, 2.6585, 2.6575, 2.6565, 2.6557, 2.6554, 3.0698, 3.069, 3.0688, 3.067, 3.0662, 3.0651, 3.0645, 3.0596, 3.0593, 3.0566, 3.055, 3.0542, 3.054, 3.0537, 3.0532, 3.052, 3.0511, 3.0492, 3.0467, 3.0456, 3.0433, 3.0418, 3.0416, 3.0405, 3.0384, 3.0377, 3.0365, 3.0351, 3.0335, 3.0328, 3.1078, 3.1072, 3.1064, 3.1051, 3.1047, 3.1041, 3.0982, 3.0976, 3.0975, 3.0944, 3.0936, 3.0933, 3.0929, 3.0917, 3.091, 3.0908, 3.0872, 3.0852, 3.0846, 3.0804, 3.0785, 3.0783, 3.0762, 3.0724, 3.0712, 3.0707, 3.0681, 3.0678, 3.0676, 3.0671, 3.2669, 3.2651, 3.2648, 3.2608, 3.2564, 3.2546, 3.2535, 3.2488, 3.2446, 3.2437, 3.2435, 3.2428, 3.2427, 3.2425, 3.2416, 3.2386, 3.2375, 3.236, 3.2358, 3.2357, 3.2339, 3.2319, 3.2275, 3.2275, 3.2273, 3.2272, 3.2266, 3.2241, 3.2227, 3.2192]}, \"token.table\": {\"Topic\": [4, 10, 10, 4, 3, 6, 9, 7, 2, 1, 2, 6, 9, 7, 9, 3, 6, 3, 4, 4, 1, 9, 1, 3, 3, 5, 1, 3, 10, 3, 4, 10, 3, 4, 1, 10, 10, 6, 8, 10, 3, 8, 9, 6, 7, 4, 7, 6, 3, 6, 8, 2, 9, 5, 2, 4, 10, 4, 9, 10, 2, 1, 7, 5, 8, 4, 8, 5, 8, 3, 7, 3, 6, 9, 5, 5, 5, 4, 9, 6, 8, 10, 7, 7, 6, 3, 10, 5, 5, 1, 3, 4, 6, 2, 2, 4, 6, 1, 7, 5, 1, 8, 6, 5, 3, 4, 9, 1, 9, 5, 7, 3, 1, 10, 4, 7, 3, 7, 2, 8, 3, 7, 10, 1, 6, 9, 10, 7, 5, 8, 8, 1, 3, 3, 1, 1, 7, 6, 2, 4, 3, 1, 8, 8, 8, 2, 9, 2, 6, 6, 4, 10, 3, 8, 5, 2, 7, 6, 2, 2, 1, 2, 9, 1, 6, 4, 4, 9, 10, 2, 8, 7, 7, 4, 3, 1, 4, 1, 6, 8, 3, 2, 2, 10, 2, 7, 7, 9, 8, 8, 10, 2, 1, 10, 7, 4, 2, 4, 1, 6, 9, 9, 8, 9, 7, 6, 5, 1, 1, 10, 8, 6, 4, 5, 10, 9, 7, 9, 10, 5, 7, 7, 10, 1, 5, 5, 4, 10, 2, 4, 7, 2, 5, 5, 9, 3, 10, 7, 9, 10, 8, 8, 4, 6, 9, 3, 8, 7, 6, 8, 1, 1, 2, 3, 2, 1, 6, 5, 9, 1, 5, 4, 6, 2, 8, 3, 9, 5, 2, 9, 5, 5, 2, 6, 7, 10, 9, 9, 1, 10, 5, 6, 3, 10, 3, 8, 4, 5, 5, 8, 2, 9, 10, 1, 6, 8, 2, 5, 8, 3, 7, 4], \"Freq\": [0.9784331356450549, 0.982614870141437, 0.9730141188173218, 0.990026121346112, 0.9854086461821868, 0.9762466301120118, 0.9874021040579611, 0.9953101669719986, 0.9909429782420701, 0.9801479443157126, 0.99214525093138, 0.991884832523343, 0.9899286936670885, 0.9760892766442258, 0.9774516295530536, 0.9741247304829002, 0.9960976866289026, 0.988553813660959, 0.9786557606746746, 0.9882255342103613, 0.9884209948128018, 0.9490694731758806, 0.9998461210772226, 0.9697557379117608, 0.9927758371491544, 0.9875319877431437, 0.9911908993068681, 0.9654321601028815, 0.9540181090137081, 0.9842178082699355, 0.9714414997240921, 0.950798062050752, 0.9772125102138608, 0.9980608142361675, 0.9781543919287319, 0.9954679556162703, 0.9446548701581025, 0.9928459884472046, 0.9478246655802566, 0.9525249778918605, 0.9836495762723367, 0.9636081339930205, 0.9567802992936808, 0.9794073230535594, 0.9695696776672051, 0.9882913325666818, 0.9976851488878465, 0.9891378048884091, 0.9966854283673947, 0.9683990167486741, 0.9882693938024196, 0.9997519218019062, 0.9818246707916474, 0.9806913474799772, 0.9977066930426711, 0.9678040669173744, 0.9493862083309408, 0.9773639669488828, 0.9626710749810853, 0.9424191988951183, 0.9988946462185602, 0.9930012166494855, 0.9900781434081022, 0.9758092688437281, 0.9500596122345041, 0.9761777158356609, 0.970187747232748, 0.9898063422741891, 0.9579888978551502, 0.9724834490259845, 0.9948703058343848, 0.986392295529238, 0.9865655720568836, 0.9656637615994875, 0.9967243506768299, 0.9934800576041946, 0.9829185008004448, 0.9763574039346347, 0.9721446547179015, 0.987152941647128, 0.981447060887095, 0.9782245968245418, 0.9783992847375749, 0.9902473689468533, 0.9651039095972818, 0.9923910169442316, 0.9653363001631702, 0.9849431284810504, 0.9838036705859472, 0.9935790162310496, 0.9873587412847314, 0.9910096925331842, 0.9922452877302945, 0.9842915440698855, 0.998315146403593, 0.9839594884328231, 0.9933676495833212, 0.9971148569677297, 0.99845864362186, 0.9898598972479057, 0.9894393749778783, 0.9845410323421366, 0.9775836028668384, 0.9936898568892875, 0.9989768533541046, 0.9636240830990126, 0.9950936834809322, 0.9992388151375876, 0.9811277791243497, 0.9938387161380788, 0.9906078870993611, 0.9887552393767978, 0.985288777454316, 0.9587014980610673, 0.9902854983237421, 0.9876531214634737, 0.9793667462710474, 0.982241575477543, 0.994361061395035, 0.9790635441894934, 0.9958512407469994, 0.9824427587320647, 0.9636355713463285, 0.9918868392694126, 0.9823635833503304, 0.9627512328619727, 0.9870809589500064, 0.9904121993516584, 0.990689491596197, 0.9846489516340592, 0.9907563367545856, 0.948547741630112, 0.05084343003712494, 0.9936021182194815, 0.9864931831637173, 0.9988164585626348, 0.9936114028036556, 0.9759058781868173, 0.9964697967731607, 0.9840479885118771, 0.9925169686059727, 0.9968368313767766, 0.9874872612644021, 0.9720997821628922, 0.9831981620009407, 0.994827557058573, 0.9683378707533854, 0.9901703323687779, 0.9948081515082231, 0.9912424091519558, 0.9881642813843552, 0.9630713392989423, 0.9926204798661232, 0.9571522591299122, 0.9706252314180749, 0.995780416881057, 0.9695442178791622, 0.9806000066060548, 0.994511377846276, 0.9954145794579581, 0.9944961198014761, 0.9934859234115847, 0.9347301440761061, 0.9862913520114671, 0.9765707206307792, 0.9791463217861114, 0.9863704396774641, 0.9752630909038313, 0.9839377851904455, 0.9954082776993448, 0.9886126913452143, 0.9818158324346686, 0.9785663381125739, 0.9899542075035388, 0.9968994801920447, 0.9992801658777557, 0.9923896710058119, 0.9860420136684734, 0.9914435308074631, 0.9897750943356305, 0.9983245779870569, 0.9977100768536186, 0.9832783451051096, 0.9916951221481022, 0.9951741584873581, 0.9833410115716624, 0.9701832472368015, 0.9961883698260525, 0.9883496089758337, 0.979585595577709, 0.9741318842864808, 0.9952745916449758, 0.9817943367589358, 0.9670023891750118, 0.9824146293836367, 0.9929357678154521, 0.9975769387447364, 0.9955325904773212, 0.9933527877542123, 0.9786773975186033, 0.985130386762632, 0.9402941166458132, 0.9851129394118603, 0.9823209723076087, 0.982911904921732, 0.9694727274394798, 0.9900352922753591, 0.9982810220683073, 0.9827583421401896, 0.9801406576825, 0.9961382532470278, 0.9874115515245213, 0.991910902087807, 0.9732768133034501, 0.9946618714039769, 0.9758152316820623, 0.9824254535958383, 0.9911923990854186, 0.9575059697655836, 0.9779874992786247, 0.972858232897461, 0.9912982391289168, 0.9697112572180019, 0.9971691692591347, 0.9780285121200485, 0.9957010668987406, 0.9879725324263544, 0.9444285606193334, 0.9901682555562421, 0.9962711832210337, 0.9816037394128286, 0.9966202209070644, 0.9796192753697319, 0.9802034334726305, 0.9741558148739374, 0.9925644566604197, 0.9946836482043525, 0.9756530096414021, 0.9894035358158516, 0.9852822626822938, 0.9560481592435977, 0.9642229546833173, 0.9916581105050095, 0.9817982691478577, 0.9674358672277991, 0.9675062103958597, 0.9935620451176341, 0.9894286312414436, 0.9957337605428235, 0.9889589214959157, 0.9982415484339183, 0.9992218667012508, 0.993538734550541, 0.9879532389784328, 0.9911318157270194, 0.9942244282873469, 0.9938131341380099, 0.988091827883044, 0.9941098250407429, 0.9813552650960112, 0.997352168281772, 0.9942245574121921, 0.980423939160635, 0.9959070586260073, 0.9807448871609499, 0.9786548748931553, 0.9644763790941357, 0.9879936757921755, 0.9922491389415368, 0.980973008418889, 0.99208579160661, 0.9932608312334071, 0.9855911330168053, 0.9940502402655627, 0.9971306152895313, 0.9602982304599453, 0.9747042065270496, 0.9493867823901613, 0.9959443392634683, 0.9621349725434034, 0.9893114346843022, 0.9923774698529871, 0.9885690553937672, 0.9496829731444688, 0.9969686780551859, 0.9861942725326575, 0.9725651548851578, 0.995999476446324, 0.9944232185698939, 0.9961167078136526, 0.995016768087533, 0.9790083268292603, 0.9531344759375431, 0.9887141187486091, 0.9853267758469753, 0.9946454525133448, 0.9855948402573921, 0.9819909124891254, 0.9725156601797094, 0.9983985373944948, 0.9718471652823373, 0.9996654006231884], \"Term\": [\"accept\", \"account\", \"actually\", \"again\", \"ah\", \"all\", \"allow\", \"also\", \"always\", \"american\", \"amp\", \"animal\", \"anti\", \"ask\", \"attack\", \"a\\u0153\", \"back\", \"bad\", \"ball\", \"ban\", \"bangaloreriot\", \"bat\", \"be\", \"beat\", \"become\", \"believe\", \"big\", \"birthday\", \"bjp\", \"bless\", \"blessing\", \"bowler\", \"bring\", \"brother\", \"brotherhood\", \"call\", \"cause\", \"celebrate\", \"celebration\", \"change\", \"channel\", \"child\", \"christian\", \"chuslim\", \"city\", \"claim\", \"come\", \"community\", \"country\", \"cow\", \"cpl\", \"cricket\", \"culture\", \"dangerous\", \"day\", \"dear\", \"defend\", \"destroy\", \"die\", \"disgrace\", \"do\", \"don\", \"dona\", \"dream\", \"eat_meat\", \"ecb_cricket\", \"eid\", \"end\", \"enemy\", \"englandcricket\", \"even\", \"ever\", \"everyday\", \"evil\", \"extremist\", \"face\", \"fake\", \"family\", \"far\", \"fear\", \"feel\", \"fellow\", \"few\", \"fight\", \"find\", \"first\", \"flexible\", \"follow\", \"force\", \"forget\", \"free\", \"friend\", \"fuck\", \"game\", \"get\", \"girl\", \"give\", \"go\", \"good\", \"great\", \"group\", \"guy\", \"hai\", \"happen\", \"happy\", \"hard\", \"hate\", \"have\", \"hell\", \"help\", \"here\", \"hijri\", \"hindu\", \"history\", \"home\", \"honor\", \"hope\", \"host\", \"how\", \"hsajwanization\", \"https_co\", \"human\", \"humanity\", \"ia\", \"ideology\", \"indeed\", \"india\", \"indian\", \"ipl\", \"isis\", \"islam\", \"islamic\", \"islamic\", \"islamicnewyear\", \"ita\", \"jehadi\", \"jihadi\", \"job\", \"just\", \"khanumarfa\", \"kill\", \"know\", \"last\", \"law\", \"lead\", \"leave\", \"left\", \"legend\", \"let\", \"life\", \"like\", \"listen\", \"live\", \"lol\", \"long\", \"look\", \"lose\", \"lot\", \"love\", \"make\", \"man\", \"match\", \"mate\", \"mean\", \"member\", \"mention\", \"miss\", \"mob\", \"month\", \"more\", \"most\", \"msdhoni\", \"msdhoni_narendramodi\", \"much\", \"muharram\", \"muslim\", \"name\", \"nation\", \"need\", \"never\", \"new\", \"now\", \"old\", \"one\", \"only\", \"organisation\", \"organization\", \"other\", \"own\", \"parent\", \"peace\", \"people\", \"person\", \"photo\", \"pisslam\", \"place\", \"play\", \"player\", \"police\", \"political\", \"post\", \"power\", \"prophet\", \"proud\", \"pure\", \"quote\", \"quran\", \"radical\", \"rape\", \"rapist\", \"re\", \"read\", \"real\", \"reason\", \"religion\", \"remember\", \"respect\", \"right\", \"riot\", \"run\", \"sambitswaraj\", \"same\", \"save\", \"say\", \"season\", \"see\", \"send\", \"series\", \"show\", \"sister\", \"slave\", \"so\", \"sound\", \"sport\", \"squad\", \"st\", \"start\", \"state\", \"still\", \"stop\", \"strong\", \"stupid\", \"support\", \"supporter\", \"sure\", \"tahunbaruislam\", \"take\", \"talk\", \"team\", \"tell\", \"terrorism\", \"terrorist\", \"test\", \"th\", \"thank\", \"then\", \"there\", \"thing\", \"think\", \"threat\", \"time\", \"today\", \"together\", \"too\", \"touch\", \"travel_ban\", \"trigger\", \"true\", \"try\", \"tweet\", \"understand\", \"use\", \"ve\", \"verse\", \"very\", \"violence\", \"wait\", \"wake\", \"want\", \"war\", \"watch\", \"way\", \"well\", \"western\", \"when\", \"where\", \"white\", \"why\", \"win\", \"wish\", \"woman\", \"wona\", \"wonder\", \"word\", \"work\", \"world\", \"write\", \"wrong\", \"xa\", \"year\", \"young\", \"\\u00f0y\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 6, 8, 1, 5, 4, 9, 10, 7, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el771091406533345271042543378252\", ldavis_el771091406533345271042543378252_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el771091406533345271042543378252\", ldavis_el771091406533345271042543378252_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el771091406533345271042543378252\", ldavis_el771091406533345271042543378252_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.063907  0.452514       1        1  28.389558\n",
       "5     -0.041658 -0.444581       2        1  18.183660\n",
       "7     -0.364975 -0.209605       3        1   9.071634\n",
       "0     -0.313363  0.235066       4        1   9.033115\n",
       "4      0.262150 -0.273115       5        1   8.669374\n",
       "3      0.389849 -0.007786       6        1   6.933906\n",
       "8      0.228447  0.288072       7        1   6.849595\n",
       "9     -0.017744 -0.126907       8        1   4.624469\n",
       "6     -0.223672  0.017626       9        1   4.447175\n",
       "1      0.144873  0.068716      10        1   3.797515, topic_info=          Term         Freq        Total Category  logprob  loglift\n",
       "6           be  5123.000000  5123.000000  Default  30.0000  30.0000\n",
       "15          ðy  1521.000000  1521.000000  Default  29.0000  29.0000\n",
       "58     cricket  1783.000000  1783.000000  Default  28.0000  28.0000\n",
       "12      muslim  1870.000000  1870.000000  Default  27.0000  27.0000\n",
       "10       happy   839.000000   839.000000  Default  26.0000  26.0000\n",
       "...        ...          ...          ...      ...      ...      ...\n",
       "849     bowler    20.137758    21.034961  Topic10  -4.9006   3.2272\n",
       "1568  flexible    19.821078    20.718168  Topic10  -4.9165   3.2266\n",
       "2433     photo    18.750808    19.648349  Topic10  -4.9720   3.2241\n",
       "5164  disgrace    18.201897    19.099781  Topic10  -5.0017   3.2227\n",
       "1986    wonder    16.938698    17.835888  Topic10  -5.0736   3.2192\n",
       "\n",
       "[332 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "209       4  0.978433    accept\n",
       "1158     10  0.982615   account\n",
       "1098     10  0.973014  actually\n",
       "1210      4  0.990026     again\n",
       "840       3  0.985409        ah\n",
       "...     ...       ...       ...\n",
       "1500      5  0.981991     wrong\n",
       "1286      8  0.972516        xa\n",
       "5         3  0.998399      year\n",
       "2684      7  0.971847     young\n",
       "15        4  0.999665        ðy\n",
       "\n",
       "[302 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 6, 8, 1, 5, 4, 9, 10, 7, 2])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=30)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
